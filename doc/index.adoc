= Spring Data Flow demo
Based on official Spring Boot / Cloud documentation: https://spring.io/projects
:toc: left
:toclevels: 4

Microservice based Streaming and Batch data processing for Cloud Foundry and Kubernetes.

Spring Cloud Data Flow provides tools to create complex topologies for streaming and batch data pipelines.
The data pipelines consist of Spring Boot apps, built using the Spring Cloud Stream or Spring Cloud Task microservice frameworks.

Spring Cloud Data Flow supports a range of data processing use cases, from ETL to import/export, event streaming, and predictive analytics.

include::features.adoc[leveloffset=0]

== Components for streaming

.Server components according to https://dataflow.spring.io/docs/stream-developer-guides/getting-started/stream/
image::architecture-sdf.png[align=center]

NOTE: The Data Flow Server and Skipper Server need to have an RDBMS installed.
By default, the servers use an embedded H2 database.
You can configure the servers to use external databases.
The supported databases are H2, HSQLDB, MariaDB, Oracle, Postgresql, DB2, and SqlServer.
The schemas are automatically created when each server starts.

include::server-dataflow.adoc[leveloffset=+1]
include::server-skipper.adoc[leveloffset=+1]

kafka-broker & zookeeper postgres

include::scs.adoc[leveloffset=+1]
